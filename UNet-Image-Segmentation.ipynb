{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing UNet Architecture From Scratch Using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import torchvision as TV\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet Model Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom UNet model\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Encoder Block\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.enc4 = self.conv_block(256, 512)\n",
    "        self.pool = self.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Transposed Convolutions Block\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "\n",
    "        # Decoder Block\n",
    "        self.dec1 = self.conv_block(512, 256)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        self.dec3 = self.conv_block(128, 64)\n",
    "\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "\n",
    "    # Define Convolutions block for reusability\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    # Forward Method\n",
    "    def forward(self, x):\n",
    "\n",
    "        x1 = self.enc1(x)\n",
    "        x2 = self.enc2(self.pool(x1))\n",
    "        x3 = self.enc3(self.pool(x2))\n",
    "        x4 = self.enc4(self.pool(x3))\n",
    "\n",
    "        x = self.upconv3(x4)\n",
    "        x = t.cat([x, x3], dim=1)\n",
    "        x = self.dec1(x)\n",
    "\n",
    "        x = self.upconv2(x)\n",
    "        x = t.cat([x, x2], dim=1)\n",
    "        x = self.dec2(x)\n",
    "\n",
    "        x = self.upconv1(x)\n",
    "        x = t.cat([x, x1], dim=1)\n",
    "        x = self.dec3(x)\n",
    "        \n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LungSegmentationDataset(t.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, image_transform=None, mask_transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.image_filenames = sorted(os.listdir(image_paths))\n",
    "        self.mask_filenames = sorted(os.listdir(mask_paths))\n",
    "        self.image_transform = image_transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_dir = os.path.join(self.image_paths, self.image_filenames[idx])\n",
    "        mask_dir = os.path.join(self.mask_paths, self.mask_filenames[idx])\n",
    "\n",
    "        image = Image.open(image_dir).convert('RGB')\n",
    "        mask = Image.open(mask_dir).convert('L')\n",
    "\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "\n",
    "        mask = mask.squeeze(0)\n",
    "        mask = t.where(mask > 0, 1, 0).float()\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image & Mask Transoformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "mask_transform = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = \"/content/drive/MyDrive/Chest X-Ray Dataset/images\"\n",
    "masks_path = \"/content/drive/MyDrive/Chest X-Ray Dataset/mask\"\n",
    "\n",
    "\n",
    "dataset = LungSegmentationDataset(images_path, masks_path, image_transform=image_transform, mask_transform=mask_transform)\n",
    "\n",
    "# Split data into training and validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = t.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "dataloader_train = t.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "dataloader_val = t.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(3, 1).cuda()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = t.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training and Validation Loop\n",
    "num_epochs = 10\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, masks in dataloader_train:\n",
    "        images = images.cuda()\n",
    "        masks = masks.cuda()\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(dataloader_train)\n",
    "    train_losses.append(train_loss)\n",
    "    print(f\"Epoch {epoch}/{num_epochs}, Training Loss: {train_loss}\")\n",
    "\n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with t.no_grad():\n",
    "        for images, masks in dataloader_val:\n",
    "            images = images.cuda()\n",
    "            masks = masks.cuda()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss = val_loss / len(dataloader_val)\n",
    "    val_losses.append(val_loss)\n",
    "    print(f\"Epoch {epoch}/{num_epochs}, Validation Loss: {val_loss}\")\n",
    "\n",
    "# Plot Training and Validation Losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label=\"Training Loss\")\n",
    "plt.plot(range(1, num_epochs + 1), val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_visualize(model, dataset, num_samples=5):\n",
    "    model.eval()\n",
    "    indices = t.randint(0, len(dataset), (num_samples,))\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        image, true_mask = dataset[idx]\n",
    "        image = image.unsqueeze(0).cuda()\n",
    "\n",
    "        with t.no_grad():\n",
    "            pred_mask = model(image)\n",
    "            pred_mask = t.sigmoid(pred_mask).squeeze().cpu().numpy()\n",
    "\n",
    "        pred_mask = (pred_mask > 0.5).astype(float)\n",
    "\n",
    "        plt.subplot(num_samples, 4, i * 4 + 1)\n",
    "        plt.imshow(image.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(num_samples, 4, i * 4 + 2)\n",
    "        plt.imshow(true_mask.squeeze(0).cpu(), cmap=\"gray\")\n",
    "        plt.title(\"True Mask\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(num_samples, 4, i * 4 + 3)\n",
    "        plt.imshow(pred_mask, cmap=\"gray\")\n",
    "        plt.title(\"Predicted Mask\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(num_samples, 4, i * 4 + 4)\n",
    "        plt.imshow(image.squeeze(0).permute(1, 2, 0).cpu())  # Original image\n",
    "        plt.imshow(pred_mask, cmap=\"jet\", alpha=0.5)  # Overlay mask\n",
    "        plt.title(\"Overlay\")\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_and_visualize(model, val_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
