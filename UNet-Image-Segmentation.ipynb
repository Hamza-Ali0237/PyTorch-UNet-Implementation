{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing UNet Architecture From Scratch Using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import torchvision as TV\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNet Model Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom UNet model\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Encoder Block\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.enc4 = self.conv_block(256, 512)\n",
    "        self.pool = self.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Transposed Convolutions Block\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "\n",
    "        # Decoder Block\n",
    "        self.dec1 = self.conv_block(512, 256)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        self.dec3 = self.conv_block(128, 64)\n",
    "\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "\n",
    "    # Define Convolutions block for reusability\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    # Forward Method\n",
    "    def forward(self, x):\n",
    "\n",
    "        x1 = self.enc1(x)\n",
    "        x2 = self.enc2(self.pool(x1))\n",
    "        x3 = self.enc3(self.pool(x2))\n",
    "        x4 = self.enc4(self.pool(x3))\n",
    "\n",
    "        x = self.upconv3(x4)\n",
    "        x = T.cat([x, x3], dim=1)\n",
    "        x = self.dec1(x)\n",
    "\n",
    "        x = self.upconv2(x)\n",
    "        x = T.cat([x, x2], dim=1)\n",
    "        x = self.dec2(x)\n",
    "\n",
    "        x = self.upconv1(x)\n",
    "        x = T.cat([x, x1], dim=1)\n",
    "        x = self.dec3(x)\n",
    "        \n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LungSegmentationDataset(t.utils.Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, image_transform=None, mask_transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.image_transform = image_transform\n",
    "        self.mask_transform = mask_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        mask = Image.open(self.mask_paths[idx]).convert('L')\n",
    "\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "\n",
    "        mask = (mask > 0).float()\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image & Mask Transoformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "mask_transform = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.ToTensor()\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
